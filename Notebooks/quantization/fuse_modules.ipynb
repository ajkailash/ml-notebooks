{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e7f840c-86c4-4256-bcaf-dd42e34ed26e",
   "metadata": {},
   "source": [
    "How to fuse a list of PyTorch modules. How to compare the performance of a fused model with non-fused version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a36521d-2d7f-447c-bd80-b94b2a51d5dd",
   "metadata": {},
   "source": [
    "### Define the example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "255d126f-e3ec-42cc-b76a-f097c4448e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf1680a-f1d5-440b-9ca2-8f822fec291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnnotatedConvBnReluModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AnnotatedConvBnReluModel, self).__init__()\n",
    "        self.conv = nn.Conv2d(3, 5, 3, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(5)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.contiguous()\n",
    "        x = self.quant(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30863b43-7103-4b31-ac99-ff019ac23b88",
   "metadata": {},
   "source": [
    "### Generate two models with and without fuse modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22998aeb-6be6-4c52-8abc-7c197a44288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.quantized.engine = 'qnnpack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6340687b-3780-4b7d-a81f-43d77c6eb944",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AnnotatedConvBnReluModel()\n",
    "\n",
    "def prepare_save(model, fused):\n",
    "    m = deepcopy(model)\n",
    "    model.qconfig = torch.quantization.get_default_qconfig(\"qnnpack\")\n",
    "    torch.quantization.prepare(m, inplace=True)\n",
    "    torch.quantization.convert(m, inplace=True)\n",
    "    torchscript_model = torch.jit.script(m)\n",
    "    torchscript_model_optimized = optimize_for_mobile(torchscript_model)\n",
    "    torch.jit.save(torchscript_model_optimized, \"model.pt\" if not fused else \"model_fused.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80d4e3dc-3bac-4e27-b3c4-3356e4373875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshmi-4250/miniconda3/envs/torch/lib/python3.11/site-packages/torch/ao/quantization/quantize.py:312: UserWarning: None of the submodule got qconfig applied. Make sure you passed correct configuration through `qconfig_dict` or by assigning the `.qconfig` attribute directly on submodules\n",
      "  warnings.warn(\"None of the submodule got qconfig applied. Make sure you \"\n"
     ]
    }
   ],
   "source": [
    "prepare_save(model, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55dd09bb-6950-473c-b057-bd44e34841e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fused = torch.quantization.fuse_modules(model, [['bn', 'relu']], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a15e3922-80e4-468c-862e-f958893e3574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshmi-4250/miniconda3/envs/torch/lib/python3.11/site-packages/torch/ao/quantization/observer.py:1272: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prepare_save(model_fused, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa025c8-5691-4028-a414-b13ccf988314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
