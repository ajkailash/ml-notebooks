{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32441c37-43cf-4727-bd33-8b5653b67979",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b19cbc0-aaff-4022-a098-7769821765ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of characters: 20479\n"
     ]
    }
   ],
   "source": [
    "print(f\"The total number of characters: {len(raw_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29cb65e6-6d12-4e87-a5ff-7daf7ab4e52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c158f35-fb17-4db3-b70e-a5069dd30498",
   "metadata": {},
   "source": [
    "## Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e534cea3-100d-41e6-b0a0-8594f72afbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c716da4-f0f8-451a-bd83-911a3a1295ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.split(r'([,.?_\"\\'()!]|--|\\s)', raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22274f23-8a3b-45bf-88cb-c04b9e66b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [item for item in result if item.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfd4bcbb-7a35-4478-b0ec-44eb44dd9f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4649"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4621bb7c-5d90-4af1-9a26-b132124072b6",
   "metadata": {},
   "source": [
    "## Converting Tokens to token IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8ca6df2d-5fa7-465c-b93b-08b129338cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = sorted(list(set(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7f737a20-b637-4e8e-a0d2-56e77577b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0b0d681a-5191-4404-b0b4-1aea171b0745",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4f068a61-4432-42d3-add9-2734f282fe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0ad68699-6ba4-4979-8f10-65fc58d5c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_ids = {token:idx for idx, token in enumerate(tokens)}\n",
    "ids_to_tokens = {idx:token for idx, token in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9fe98e45-4635-428d-a19a-50b0c9589495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1159"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_ids[\"<|endoftext|>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a795587-08b2-4483-9c58-c34722393177",
   "metadata": {},
   "source": [
    "## Now lets put all this together inside a python class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3d998119-476d-4947-8a7d-82592a250045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {v:k for k, v in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        print(preprocessed)\n",
    "        preprocessed = [item for item in preprocessed if item.strip()]\n",
    "        token_ids = [self.str_to_int[s] if s in self.str_to_int else self.str_to_int[\"<|unk|>\"] for s in preprocessed ]\n",
    "        return token_ids\n",
    "\n",
    "    def decode(self, token_ids):\n",
    "        decoded_str = \" \".join([self.int_to_str[id] for id in token_ids])\n",
    "        return re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', decoded_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "11749c50-78bf-4b2a-83a5-0a631dfd47d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SimpleTokenizerV1(token_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7bd54b2a-0444-4541-bbf9-272d2c5962dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join([text1, text2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "545aa25a-063a-4591-b7d2-58bb537dc0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a231da1-4fdc-41d9-8330-688c4edbae3e",
   "metadata": {},
   "source": [
    "## Byte Pair encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "96b00a1b-62d5-4606-9511-a3dba99b64db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c25d817f-95b3-45be-b4b6-eac2c7665bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "71aa4ffb-5361-4ec2-90df-cb302efb66e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "69727b5d-c96a-438b-afee-441cace2e30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15496,\n",
       " 11,\n",
       " 466,\n",
       " 345,\n",
       " 588,\n",
       " 8887,\n",
       " 30,\n",
       " 220,\n",
       " 50256,\n",
       " 554,\n",
       " 262,\n",
       " 4252,\n",
       " 18250,\n",
       " 8812,\n",
       " 2114,\n",
       " 286,\n",
       " 262,\n",
       " 20562,\n",
       " 13]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "471f14e3-7945-4e3c-8f2f-24968e9b1afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2bc3d47e-a9c7-459f-a89b-918003fb20d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33901, 86, 343, 86, 220, 959]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Akwirw ier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d52ece-556f-4780-86ce-e30c644766de",
   "metadata": {},
   "source": [
    "## Datasampling with a sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "035e8a8a-7116-4ab9-8d33-569d9ac1eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the input/target pairs\n",
    "#input: input tokens (sequence)\n",
    "#target: input tokens shifted by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c27e18cc-ca17-4355-baf8-c1f6e57d944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_text = tokenizer.encode(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3ee61cf6-85a6-4698-b44f-9438566799e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "fc8b221b-51cd-44d7-8737-21e6677950af",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c61bd1e8-0150-45f0-be2e-050c21dcef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "64c3b1be-d025-4dcd-870a-6fac662b450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e9c783f3-ba9c-473f-9115-bc1aff42a5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [40, 367, 2885, 1464]\n",
      "y:     [367, 2885, 1464, 1807]\n"
     ]
    }
   ],
   "source": [
    "print(f\"x: {x}\")\n",
    "print(f\"y:     {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b7832594-4be3-421d-a09d-93ac8a362888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I --->  H\n",
      "I H ---> AD\n",
      "I HAD --->  always\n",
      "I HAD always --->  thought\n"
     ]
    }
   ],
   "source": [
    "#only for the purpose for understanding\n",
    "#Don't confuse with dataloading\n",
    "for i in range(1, context_size+1):\n",
    "    x = enc_sample[:i]\n",
    "    y = enc_sample[i]\n",
    "    print(tokenizer.decode(x), \"--->\", tokenizer.decode([y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "9e535477-b868-4730-a3ab-2cf99f5f9992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "10a1a4ef-672c-44c4-8e98-3d4a59dd72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        for i in range(0, len(token_ids), stride):\n",
    "            input_chunk = token_ids[i:i+max_length]\n",
    "            output_chunk = token_ids[i+1:i+max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(output_chunk))\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "04e1ccdb-1ac3-470b-bc44-ad4c73033fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GPTDatasetV1(raw_text, tokenizer, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d44a5ad8-52c8-4a3b-8bde-a31f25d4ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "7589f266-96af-40d7-84c0-d8654cce13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "07cb36a4-ad13-4091-9c52-e9a04ad084f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1464,  1807,  3619,   402,   271, 10899,  2138,   257]),\n",
       " tensor([ 1807,  3619,   402,   271, 10899,  2138,   257,  7026]))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e92902a-9d23-4f3a-bbdb-a25dda7e4733",
   "metadata": {},
   "source": [
    "## Creating token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "520b3a8f-cfc2-4d15-96f4-8477981f6692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "74775f45-0b36-45b9-9034-b6b18f8b8132",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.nn.Embedding(tokenizer.n_vocab, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "56d612e1-9de7-425d-9539-d91d429ffede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings(sample[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3b6477aa-2e34-42a0-a4ad-d828ff7f33ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1464,  1807,  3619,   402,   271, 10899,  2138,   257])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1dbbb-61aa-474e-8156-17f109f7bc44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
