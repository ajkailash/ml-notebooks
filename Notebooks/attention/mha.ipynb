{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11020582-3114-40ce-b655-aa3c2d978748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d20676-b8cb-41fc-bb93-6d726f150c7b",
   "metadata": {},
   "source": [
    "### Multi-head attention\n",
    "- One way to implement multi-head attention is to use a nn.Modulelist container and hold multiple self attention modules in it\n",
    "- or you can ensure the embedding dimension is divisible by num_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75cee27f-862f-46ee-8cf3-19650d24dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out_kq, d_out_v):\n",
    "        super().__init__()\n",
    "        self.d_out_kq = d_out_kq\n",
    "        self.w_query = nn.Parameter(torch.randn(d_in, d_out_kq))\n",
    "        self.w_key = nn.Parameter(torch.randn(d_in, d_out_kq))\n",
    "        self.w_value = nn.Parameter(torch.randn(d_in, d_out_v))\n",
    "\n",
    "    def forward(self, x):\n",
    "        queries = x @ self.w_query\n",
    "        keyes = x @ self.w_key\n",
    "        values = x @ self.w_value\n",
    "\n",
    "        attn_scores = queries @ keyes.T\n",
    "\n",
    "        attn_weights = torch.softmax((attn_scores / self.d_out_kq ** 0.5), dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08723bff-b44e-42dc-9ee6-9cf4909af60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionWrapper(nn.Module):\n",
    "    def __init__(self, d_in, d_out_kq, d_out_v, num_heads):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([SelfAttention(d_in, d_out_kq, d_out_v) for _ in range(num_heads)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.cat([m(x) for m in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f394e1d-a240-479e-a919-59b367dd88d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mha = MultiHeadAttentionWrapper(3, 2, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "683e891f-143b-43af-a78f-17dba460b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((6, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83aad349-d076-43db-bfd7-b3bb33ba2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mha(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baf50bd5-d0cd-4716-b02d-99286a4e5c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a5d2c5f9-5d9e-461c-8e31-9c56343db6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHAAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out_kq, d_out_v, num_heads):\n",
    "        super().__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_out_kq = d_out_kq\n",
    "        self.d_out_v = d_out_v\n",
    "        self.num_heads = num_heads\n",
    "        self.w_query = nn.Parameter(torch.randn(d_in, d_out_kq))\n",
    "        self.w_key = nn.Parameter(torch.randn(d_in, d_out_kq))\n",
    "        self.w_value = nn.Parameter(torch.randn(d_in, d_out_v))\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_length = x.shape[0]\n",
    "        queries = x @ self.w_query\n",
    "        keyes = x @ self.w_key\n",
    "        values = x @ self.w_value\n",
    "\n",
    "        queries = queries.view(seq_length, self.num_heads, self.d_out_kq // self.num_heads)\n",
    "        keyes = keyes.view(seq_length, self.num_heads, self.d_out_kq // self.num_heads)\n",
    "        values = values.view(seq_length, self.num_heads, self.d_out_v // self.num_heads)\n",
    "\n",
    "        \n",
    "        attn_scores = queries @ keyes.transpose(-2, -1)\n",
    "\n",
    "        print(attn_scores.shape)\n",
    "\n",
    "        attn_weights = torch.softmax((attn_scores / self.d_out_kq ** 0.5), dim=-1)\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "\n",
    "        print(context_vec.shape)\n",
    "\n",
    "        # return context_vec.view(seq_length, self.num_heads * self.d_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a34cefb0-35aa-4af5-8ab5-a5c15fa502c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(6, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "45700557-6b31-4671-ab32-593bf10e27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mha = MHAAttention(16, 16, 16, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f0a7aea6-eb0e-4f62-a37f-fabb848c5e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 2, 2])\n",
      "torch.Size([6, 2, 8])\n"
     ]
    }
   ],
   "source": [
    "new_mha(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ce997-ffbc-4c10-b3b2-4ff070a8a59b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
